= ECDSA Keep Signer Selection

Selecting the participants of ECDSA keeps
has some important differences to Random Beacon group selection.
Instead of a large signing group with a honest majority,
current threshold ECDSA implementations
limit the practical group size to 3-of-3.

For use in the Keep network,
two schemes appear viable candidates:
a non-interactive sortition with lazy evaluation of eligibility,
and an adapted version of the current Random Beacon ticket-based protocol.

== Requirements

As in the Random Beacon,
we have a number of basic requirements for the selection process:

Proportionality::
Each operator's chance of being selected
is proportional to the amount of KEEP tokens backing them.

Constant group size::
We want to select 3 members.
Not 4 members, nor 2 excepting that we then proceed to select a third member.
5 members is right out.

Efficiency::
We need to select members for every ECDSA keep,
as just reusing the same 3 every time would be bad^[citation needed]^.
This means we pay the price of member selection every time.
By the theorem of money is nice to have,
we would like to avoid
giving the miners money we could instead _keep_ to ourselves.

Manipulation resistance::
It's not good if we spend a whole load of money
implementing some kind of a fancypants hunger games of a selection process
only to find that some smartass operator circumvented the rules.
It's embarrassing if someone gets to be more clever than us on-chain,
so we need to be really clever to begin with.

In addition to the basic requirements from the Random Beacon,
such as the chances of getting selected
being proportional to the operator's stake,
ECDSA keeps have a number of more involved requirements
for a viable member selection process.

=== Fully backed bonding

In addition to the normal KEEP token stake,
ECDSA keeps must be able to utilize separate bonds as collateral.
Unlike staked KEEP which may become leveraged,
operations relying on these bonded tokens (initially ETH)
must always be fully backed.

Fully backed bonding makes eligibility determination more complex.
However, we only need to apply proportionality to the staked KEEP
so bonding can be a boolean
"does this operator have enough of a bond to participate or not".

=== Privileged customer applications

Unlike in the Random Beacon,
where the customer does not matter for group selection,
ECDSA keeps must be able to have privileged customer applications
that may seize the bonded tokens at their discretion.

This means that it is not enough to ensure
that the EDCSA keep factory is authorized to slash operators.
Instead, each privileged customer must be individually authorized
to seize the selected operators' bonds.
Thus, eligibility must be determined on a per-customer basis.

To make matters more complex,
customers should not be able to interfere with each other.
If adding a new privileged customer
can increase the cost of on-chain actions for the old customers,
a variety of DOS attacks becomes possible.

=== Prohibiting visible duplicate members?

In the Random Beacon,
a single operator with a staker weight greater than 1
can have multiple members in a single signing group.
This ensures better proportionality,
reduces incentives to blitzpants
(and thus obfuscate the true level of centralization in stakes),
and is harmless when groups have tens of members
as a single operator is very unlikely to control a disproportionate fraction.

With only 3 members,
the probability of a single operator controlling the entire group
is vastly higher.
An operator with 5% of the total stake
is astronomically unlikely to have a controlling majority
of 33 in 64 members,
but would have 1 in 8,000 chance of controlling 3 in 3 members.

If such _visible duplicates_
(members controlled by the same operator address)
are permitted,
it may cause unhappiness among customers
who aren't accustomed to applying the security mindset.
Because such individuals make up the vast majority
of posts on Twitter and Hacker News,
we can't tell them to just git gud{blank}footnote:willnotjust[
As per the theorem of _People Will Not Just_;
there is not a single instance in recorded history
of people having just,
and they certainly aren't going to start now
]
and need to consider the optics of our member selection scheme.

In the actual reality
anyone planning malicious action
would most likely blitzpants
the hell out of their stakes anyway
to conceal their capabilities for nefarious coordination.
Thus the impact is only really limited
to operators starting out as honest.
And because honest whales are a wee bit less likely to be selected,
naughty blitzpantsers will be ever so slightly overrepresented
in the ECDSA keeps.

However, a legit benefit of banning visible dupes
is that a single operator's client node getting hacked
can't result in the hacker immediately running away with the BTC deposit,
no matter how lucky the unlucky operator previously was.

Prohibiting visible duplicates
harms the proportionality of the selection process
as large stakers get marginally less return from their capital,
and thus creates a slight incentive to blitzpants,
but the impact is dramatically lesser than in the Random Beacon.
Permitting visible duplicates
may also lead to implementation complications
because a single client node may need to play multiple roles simultaneously.

To ensure we don't screw up right in the beginning of the process,
this draft isn't going to commit either way on this question.
Both options will be explored.

=== Fast response time?

In the Random Beacon,
the signing group producing each entry
is selected from a pool of existing groups.
A signing group can only be called to perform work
when member selection and key generation have finished.
The only major downside of slower member selection and DKG
is that the rate of signing group creation is limited
as the current design requires any existing group creation
to finish or time out before another group creation may begin.
A future redesign to permit concurrent group creation
could eliminate this constraint.

When a request for an ECDSA keep is made,
the keep may be required right away
depending on the customer application.
Significant latency in this process is detrimental to the service.
== Common features

Some solutions to various parts of the whole question
don't vary between the candidate schemes.

=== Independent bonding contracts

We're likely to want to use currency bonding in future keep protocols.
Thus, instead of implementing bonding separately in each protocol
it is preferable to have one general-purpose bonding contract
for each bonding scheme
(a specific currency and ruleset).

Just like the staking contract,
these bonding contracts make the bond currency available
to contracts authorized by the operator's authorizer.
Unlike in the staking contract,
the fully backed bonds can either be directly transferred to keeps,
or assigned to them in the bonding contract.

=== New authorizations

When a keep/factory wants to use an operator's bond,
it needs to be authorized.
This authorization must be a part of an operator's eligibility for selection.

In the case of privileged customer applications,
the privileged application itself must be authorized.
If the privileged applications can only seize bonds,
the staking contract doesn't need to be changed to accommodate them.

===  Pooling keeps?

If ECDSA keeps are created in response to requests,
creating a keep requires acquiring a selection seed from the Random Beacon.
The Random Beacon cannot produce entries instantly,
so ECDSA keeps could only be returned through a later callback.
Any additional latency beyond the beacon entry
would add further delay to the customer receiving the keep.

If ECDSA keeps are created in advance and kept in a pool,
most requests can be served immediately from the pool
instead of requiring a later callback.

Being able to return the keep address
immediately when the customer requests a keep
would provide a superior customer experience.
However, this is impossible to guarantee
as any number of pooled keeps
can be exhausted by a greater number of keep requests
in a sufficiently short period of time.
Thus, an interface that can return a keep immediately
would need to either error out when it cannot return a keep,
requiring the customer to request again later,
or to return a newly created keep in a callback
if one isn't immediately available.
In either case the customer application must be designed
to deal with the more complex scenario.

Another advantage of pooling keeps is that keeps can be created in batches.
Standard methods exist for deriving an arbitrary number of pseudorandom numbers
from a single high-entropy seed.
If a single entry from the Random Beacon is used
to create a large number of ECDSA keeps, e.g. 20,
the cost of the beacon entry is divided among them.

Additionally, selecting a larger number of members
and dividing them among the batched keeps
may affect the characteristics of the member selection scheme
either favorably or unfavorably.

== Adapted ticket scheme

- Authorization checks are simple to perform
- Relatively small gas cost overhead,
small _n_ requires less optimization than in the Beacon
- Existing implementation can mostly be reused
- Ticket submission takes time,
and small _n_ makes it slower (!!)

The Random Beacon currently uses a scheme
where each operator has a number of virtual stakers
equal to their staker weight
(total stake divided by the minimum stake to participate),
and each virtual staker gets assigned a pseudorandom _ticket_ value
in each group selection,
with a smaller ticket value being more valuable.
The operators then submit promising tickets on-chain,
and finally the lowest _n_ tickets are selected to form the group.
Eligibility for the group selection is checked on ticket submission,
and operators are given a reasonable amount of time to submit their tickets
so they can monitor the on-chain situation
to determine their likelihood of getting selected
and thus avoid submitting unnecessary tickets.

With slight adaptation
a ticket-based scheme would be suitable
for the unique requirements of ECDSA keeps.

=== Pros

A ticket-based scheme is a decent fit for ECDSA keeps
as it provides simple solutions to many of the requirements.
Operators' bond and authorization status can be queried
when they submit their tickets
along with the rest of the eligibility check.

The cost of ticket-based selection requiring _O(n)_ transactions
is kept in check by _n = 3_,
and tracking the _n_ best tickets during submission
is likewise rather simple and inexpensive.

The Random Beacon already has a working implementation of a ticket scheme
so ECDSA member selection could ship without much extra work.

=== Cons

The downsides of ticket-based selection
are mostly the same as in the Beacon;
submitting tickets costs gas, takes time,
and is vulnerable to censorship.
The main differences to the Beacon are
that the gas costs are somewhat less of an issue,
and that the time taken is more significant.

In the Random Beacon signing groups are created ahead of time
and only chosen to perform work
when they have finished their key generation.
ECDSA keeps are created in response to demand,
so having to wait for ticket submission is more problematic.

Even worse, when only 3 members are selected
the ticket submission itself has to be slower.
With a large _n_ the variability in the values of the _n_ best tickets
is substantially lower,
and the relative impact of a redundant ticket submission is lesser.
When only the 3 best tickets matter,
both the probability and the cost of redundant submission are higher.
To compensate for this,
the ticket submission period can't be dramatically shorter,
and may even need to be longer than in the Beacon.

An actor capable of censoring on-chain transactions
may be able to manipulate the outcome.
Attacks can be targeted by calculating other operators' ticket values.
Ticket schemes can be hardened
against targeted attacks that rely on pre-calculation
at the cost of higher gas expenses
by using a signature of the selection seed as the ticket value.
Miner censorship attacks aren't affected by this mitigation.

=== Batched selection

If ECDSA keeps are created in batches,
it has both positive and negative effects on ticket-based member selection.

The upside of selecting a larger number of members at once
is that the risk of redundant ticket submissions is lessened.
30 members do not require 10 times the ticket submission time as 3 members.

The downside is that the cost of ticket submission
scales with the number of members selected at once.
With 3 members tracking the 3 best tickets is simple and inexpensive.
Tracking and ordering the 60 best tickets
requires significantly more optimization.
Ticket-based selection has theoretically _O(n^2^)_ cost.

=== Implementation

As in the Beacon,
operators calculate and submit tickets.
Unlike the Beacon,
we only need to store the 3 best tickets
and can just read+compare each submitted ticket to all of them.

If we prohibit visible duplicate members
yet operator _P_ submits a ticket
while the best 3 tickets already have a ticket from _P_,
only the better of the two tickets is kept
and the other one is discarded.

Ticket-based selection has a practical cost floor of
_21,000 + 2,400 + 5,000 = 28,400_ gas per ticket
for _n = 3_
(transaction base fee + 3 read operations + 1 write).
The total cost floor is _85,200_ gas.

== Implementation

=== Bonding contract

The bonding contract makes Ethereum bonds available as collateral
for operator contracts and privileged customer applications.

Unlike staked KEEP,
the proportionality requirement does not apply to currency bonding.
However, once an amount of ETH is bonded as collateral for an operation
it is tied to the specific operation until freed,
and unavailable for other operations.

==== Unbonded value

ETH that an operator has available for bonding
but that has not been assigned for any specific bond
is recorded in `unbondedValue`.

Anyone can add bonding ETH to an operator at any time
by calling `deposit(operator)` with a payment.
The amount of ETH received by the bonding contract
is added to the specified `operator`'s `unbondedValue`.

An operator can withdraw some or all of their unbonded value
at any time by calling `withdraw(amount, destination)`.
If the specified `amount` is less than the `unbondedValue[msg.sender]`,
it is transferred to the address `destination`.

`mapping(address operator => uint) unbondedValue`::

`payable deposit(address operator)`::

`withdraw(uint amount, address destination)`::

==== Authorizations

As with the staking contract,
operator contracts must be authorized by an operator's authorizer
in order to create bonds.
Once a bond has been created by an authorized operator contract
it can be reassigned at will to any other contract.
The current holder of a bond may reassign, seize or free it at will.
An authorized operator contract is expected
to treat bonds it creates with appropriate caution.

Additionally, privileged customer applications
that wish to have the authority to cause operators' bonds to be seized
should be identified to the bonding contract
and authorized by an operator's authorizer.
However, seizing a bond based on input from a privileged customer application
is actually performed by the holder of the bond,
so this authorization is absolutely non-enforceable
and serves as more of a sanity check.
Authorized operator contracts are expected
to play nice and honor this sanity check,
and operators' authorizers are expected
to not authorize operator contracts that do not respect the sanity check.

Authorized operator contracts and authorized privileged customers
are recorded in the bonding contract
as `authorizedOperatorContracts[authorizer]`
and `privilegedCustomers[authorizer]` respectively.
As with the staking contract,
all operators using `authorizer` as their authorizer
share the authorizations.
To reduce cross-contract calls to the staking contract,
positive authorizations can be cached in the bonding contract.

==== Creating a bond

Similarly to the staking contract,
the bonding contract provides a single function
operator contracts can use to determine whether a bond can be created.
`availableUnbondedValue(operator, privilegedCustomer)`
performs all the applicable authorization checks 
and returns the amount of ETH that can be bonded
from the `operator`, to the caller `msg.sender`,
and trusting the `privilegedCustomer` if present.

To actually create a bond,
an operator contract calls
`createBond(operator, amount, reference, privilegedCustomer)`.
This performs the same checks as `availableUnbondedValue()`
and if the amount available for the requested bond
is equal or greater than the requested `amount`,
the bond `amount` is subtracted from the `unbondedValue` of the operator
and the bond is created at `lockedBonds[operator, msg.sender, reference]`.
The `reference` is additionally recorded at
`bondAssignments[operator, msg.sender]`.
If the amount available is less than requested,
`createBond()` returns an error.

`availableUnbondedValue(address operator, address optional privilegedCustomer)`

`createBond(address operator, uint amount, uint reference, address optional privilegedCustomer)`.

`mapping(address operator, address holder, uint reference => uint) lockedBonds`

`mapping(address operator, address holder => uint[]) bondAssignments`

==== Assigned bonds

When an operator joins an operation requiring a bond
it is subtracted from the `unbondedValue` of the operator,
and a bond is created.
The created bond is identified by the address of the `operator`,
the address of the operator contract that is the `holder` of the bond,
and the `reference` identifier of the specific bond.

The specific bond is recorded in `lockedBonds`,
and the `reference` is added to the list of `bondAssignments`
corresponding to the `operator, holder` pair.

The `holder` of a bond can reassign it
to a different holder and/or reference
by calling `reassign(operator, reference, newHolder, newReference)`.
This removes the bond `lockedBonds[operator, holder, reference]`
and creates a new bond at `lockedBonds[operator, newHolder, newReference]`.

The `holder` of a bond can seize some or all of a locked bond
by calling `seizeBond(operator, reference, amount)`.
The specified `amount` must be
equal or less than the bond at `lockedBonds[operator, holder, reference]`.
The `amount` is subtracted from the bond
and transferred to the `holder`.

The `holder` of a bond can free the bond
by calling `freeBond(operator, reference)`.
The bond at `lockedBonds[operator, holder, reference]` is removed
and the bonded amount is added to `unbondedValue[operator]`.

`reassign(address operator, uint reference, address newHolder, uint newReference)`

`seizeBond(address operator, uint reference, uint amount)`

`freeBond(address operator, uint reference)`

=== Signer selection

For V1 we can minimize implementation effort
by lifting most of a ticket-based scheme straight from the Beacon.
Only a few differences are required:

- When a valid ticket is submitted and accepted,
a corresponding bond is created.
If the ticket is later replaced by a ticket with a lower value,
the replaced ticket's bond is freed.

- When ticket submission has ended,
the tickets are divided into groups of 3.
It's not immediately clear
how visible duplicates among the tickets should be dealt with,
if visible duplicates in ECDSA keeps are prohibited.
Distributing duplicate members first
and then filling the remaining spots with non-dupes
has some unlikely but annoying edge cases
such as a single operator getting more than 1/3 of the tickets.

- When the ECDSA keeps are created,
the bonds of their members are reassigned from the factory to the keeps.

- To compensate for locking bonds right away,
the selected operators are rewarded
when a keep successfully completes key generation.
If a keep fails to generate a key,
the bonds are released and no compensation is paid out.
This acts as further incentive for the operators to finish DKG.
These rewards are paid out from a dedicated reward pool,
and payments from depositers are added to the pool.

=== Batching

We want to create keeps in batches
for a variety of reasons
like ensuring we aren't limited by beacon throughput,
and improving cost-efficiency because we pay less to beacon gas fees.

One _batch_ is created for every _epoch_.
A batch involves creating one or more keeps,
realistically more.
Because demand for keeps is expected to fluctuate,
we need to account for it somehow.
Either the batch size or epoch length, or both,
has to accommodate changes in demand.

==== Responding to demand

===== Flexible batches and fixed epochs

Number of keeps per batch responds to demand,
epoch length held constant.

This isn't very good
because ticket submission costs scale _O(n^2^)_.
With our optimizations we can cope with 64 members in the beacon
making ~20 keeps per batch realistic,
but in the face of serious growth this is non-viable.

===== Fixed batches and flexible epochs

Number of keeps per batch constant,
epoch length responds to demand.

Every time we've provided _batch size_ keeps to customers,
we create another batch.
This doesn't mean the _pool size = batch size_
as we can keep some keeps in reserve.

We're theoretically still limited by the beacon throughput,
just multiplied by _batch size_.

===== Flexible batches and flexible epochs

Both keeps per batch and epoch length responds to demand.

If we keep batches constant until we hit beacon limits,
and then start increasing batch size,
it probably provides the best way to scale on the current beacon.

==== Batching and privileged customers

Batching keeps without privileged customers is simple.
However, each privileged customer requires its own batch
to ensure that all selected signers have authorized the privileged customer.
This implies keeping separate keep pools each privileged customer,
similar to sortition pools.
With privileged customers that have a high demand for keeps,
this is not a problem as any keeps created in a batch
will be requested in a reasonable time.
With privileged customers that require keeps only rarely,
creating full-sized batches can lead to keeps being unused.

To cope with this,
the _minimum batch size_ should be 1.
Batch size should respond to demand enough
so that both high-demand and low-demand customers can be served.

=== Ticket pool

We don't actually need to create keeps in batches;
it's sufficient to pool received tickets
and create keeps on demand,
using the tickets like a queue.

Each privileged customer has their own ticket pool and request queue.
Keeps without a privileged customer share one pool and queue
regardless of the customer address.
Where a privileged customer is specified,
it may also be "none".

Tickets in the ticket pool are _unassigned_
and available for populating a requested keep.

The validity of a ticket
(and the respective operator's eligibility for work selection)
is evaluated upon both submission and assignment.

==== Serving requests

When a request for a keep is received,
the factory tries to create a keep
using unassigned tickets in the ticket pool.

Starting from the first (lowest-valued, with some caveats) ticket,
unassigned tickets are evaluated for validity,
and prospectively assigned to the request.

Tickets that are no longer valid
(e.g. due to not having sufficient ETH available for bonding anymore)
are discarded.

If a visible duplicate would be selected,
i.e. a ticket from an operator
whose earlier ticket has already been assigned to the request,
the second ticket is skipped for the purposes of the current request
but not discarded.
This may trigger a pool refill under unexpected circumstances.

If only 1 or 2 tickets can be assigned to the request,
the request remains pending while the ticket pool is refilled.
If all 3 required tickets can be assigned to the request,
the assigned operators have their bonds created
and are expected to begin the keep creation process.
This should not lead to weird behavior
because we just checked for their eligibility earlier in the same call
and visible dupes are prohibited
(visible dupes could run out of bond for the second or third signer
even if the bond appears ok).
If it nonetheless does,
we switch to creating the bond when the operator is prospectively assigned,
and freeing it if the operator is unassigned
because we can't populate the keep.

When tickets are actually assigned,
they are removed from the ticket pool.

==== Pool refill

===== Triggering a ticket pool refill

Ticket pool refill can be triggered on any of the following conditions:

- The factory has received a request for a keep,
but there are insufficient unassigned tickets for the request.

- The factory has received a request for a keep,
but the previous ticket submission
was at least _maximum epoch length_ time ago,
so the tickets have expired.

////
- The factory has received a request for a keep,
and it has enough unassigned tickets for the request
but the number of remaining tickets
is insufficient for the customer's _constant pool_.
////

===== Acquiring the selection seed

When a pool refill has been triggered,
any operator can submit a transaction
calling the factory to request a _beacon entry_ from the random beacon.
The operator is reimbursed for the cost of the call.

This is a separate transaction from the customer requesting a keep,
to ensure that the cost of requesting a keep
stays steady and predictable.

When the beacon has generated the entry,
it performs the callback from the request
which begins the ticket submission.

The _beacon entry_ is salted with some identifier
(e.g. the address of the factory)
to make sure that we get different outputs
than a possible beacon group selection.
(We should probably salt the beacon too,
just for consistency.)
The salted entry becomes the _selection seed_
and is used as an input for ticket value calculation,
alongside operator address and virtual staker index.

===== Number of tickets

When the _selection seed_ is acquired,
the factory determines how many tickets it requests
in this pool refresh.
Because more requests may have arrived while waiting for the beacon,
////
and because the pool refresh may have been triggered
by the need to maintain a _constant pool_,
////
the number of currently pending keep requests may not be 1.

Each privileged customer's ticket pool
stores their _current queue size_,
which specifies how many keeps
that customer is expected to request within a ticket epoch.

If pool refresh is called
because insufficient tickets were available to assign to a request,
and the time since the previous pool refresh
is less than the _minimum epoch length_,
the _current queue size_ is increased by 1
limited by the _maximum queue size_.

If pool refresh is called
due to more than _maximum epoch length_ time having passed,
and the pool had unassigned tickets that thus expired,
the _current queue size_ is decreased by 1
limited by the minimum of 1.
If the time since the last refill is greater than _N * maximum epoch length_,
and the number of expired tickets is equal or greater than _3N_,
where _N >= 2_,
we decrease the _current queue size_ by _N_ instead of 1.

If pool refresh is called
due to more than _maximum epoch length_ time having passed,
but all previous tickets had been assigned,
the _current queue size_ remains unchanged.
The same applies if pool refresh is called
due to running out of unassigned tickets for the pending requests,
but the time elapsed since previous pool refresh
is between the _minimum_ and _maximum epoch length_.

After the _current queue size_ has been adjusted,
the tickets to be requested are calculated.

The number of tickets required in this epoch
is calculated by:

`requestedTickets = max(currentQueueSize, pendingRequests) * 3 - unexpiredUnassignedTickets`

===== Ticket submission

Tickets are submitted as in the beacon,
except for the additional eligibility checks
for bond status and privileged customer authorization.

Once the ticket submission time is over,
the received tickets (in order from low to high)
are concatenated to any unexpired unassigned tickets already in the pool.

==== Constant pool

If a privileged customer has a sustained high demand for keeps,
we may implement a _constant pool_
that tries to prevent the ticket pool from ever becoming entirely empty.
If the customer is eligible for a constant pool,
their ticket pool is refilled when the number of unassigned tickets
falls below the constant pool threshold.

The constant pool is probably out of scope for now
and we may want to move to sortition pools early enough
that it won't matter anyway.
Thus, further details have been omitted.

==== Funding

To refill the ticket pool,
we need an entry from the Beacon.
As any keep request can lead to requesting a beacon entry,
it seems necessary to set the price of a keep request
to cover the beacon entry.
When the ticket pool is used to stretch one entry for multiple keeps,
we can donate the created surplus to the beacon.

A pool refill requires operators to submit tickets.
The reward for submitting a ticket
is a reasonable probability of getting selected to a keep later.
Operators that have a problem with this can simply not submit.

Operators' bonds are locked only when they are actually assigned to a keep,
so we don't need to worry about that part either.

=== Or just skip the pool altogether?

In this option we treat privileged customers separately,
but don't pool tickets for later use.
When a request for a keep is received
we request an entry from the Random Beacon.
When we get the entry
we have the operators submit `3 * pendingRequests` tickets,
and then create the keeps for the submitted tickets.

This is a lot simpler to implement
and works just as well at particularly high levels of demand.
If we get more requests
between requesting the selection seed and beginning ticket submission
we can immediately adapt the number of tickets we request.
If we get more requests
while ticket submission is ongoing,
we go immediately back to requesting a beacon entry
when the ticket submission finishes.
Thus, neither the beacon nor ticket submission act as bottlenecks
(except if we hit the cap of how many tickets can be requested at once).

If sequential ticket submission hits _O(n^2^)_ too hard
we can just run ticket submissions in parallel,
requesting the selection seed for another one
when the previous seed is received.

This doesn't scale as well
when the interval between requests is longer than the entry+ticket latency
but shorter than the epoch we'd use for ticket pools.
However, the lack of ticket pool complexity makes the gas costs lower
and also did I mention the low development effort?
